{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13f50d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file math-rollouts/deepseek-r1-distill-llama-8b/temperature_0.6_top_p_0.95/correct_base_solution/problem_330/chunk_0/solutions.json was not found.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Define the base directory for the problem files\n",
    "problem_dir = \"math-rollouts/deepseek-r1-distill-llama-8b/temperature_0.6_top_p_0.95/correct_base_solution/problem_330\"\n",
    "\n",
    "# The directory containing the solution file\n",
    "chunk_dir = \"chunk_0\"\n",
    "# The name of the solution file\n",
    "chunk_filename = \"solutions.json\"\n",
    "\n",
    "# Construct the full path to the solutions.json file\n",
    "chunk_path = os.path.join(problem_dir, chunk_dir, chunk_filename)\n",
    "\n",
    "try:\n",
    "    with open(chunk_path, 'r') as f:\n",
    "        # Load the JSON content from the file\n",
    "        chunk_data = json.load(f)\n",
    "\n",
    "    print(f\"Content of {chunk_filename}:\")\n",
    "    # Pretty-print the JSON object for better readability\n",
    "    print(json.dumps(chunk_data, indent=2))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {chunk_path} was not found.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: The file {chunk_path} is not a valid JSON file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig, AutoModelForCausalLM, pipeline\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\" # Or any other suitable model\n",
    "\n",
    "mname = model_name\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Important: Add a pad token if the tokenizer doesn't have one, especially for decoder models.\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with `output_attentions=True`\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_attentions=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa82177",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = chunk_data[0]['full_cot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input text\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Pass the inputs to the model\n",
    "# The output will include a tuple of attention weights, one for each layer\n",
    "outputs = model(**inputs, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49010be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = outputs.attentions\n",
    "\n",
    "# Print the shape of the attention weights for each layer\n",
    "print(\"Attention weights shape for each layer:\")\n",
    "for i, layer_attentions in enumerate(attention_weights):\n",
    "    print(f\"Layer {i}: {layer_attentions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade70d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46dfd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310251a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layer and head you want to visualize\n",
    "layer_index = 0\n",
    "head_index = 0\n",
    "\n",
    "# Extract the attention pattern for the specified layer and head\n",
    "if layer_index < len(attention_weights):\n",
    "    layer_attention = attention_weights[layer_index]\n",
    "    # Squeeze the batch dimension\n",
    "    attention_pattern = layer_attention.squeeze(0)\n",
    "    # Get the specific head's attention matrix and detach from the graph\n",
    "    head_attention = attention_pattern[head_index].detach().numpy()\n",
    "\n",
    "    # Create the heatmap visualization\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # sns.heatmap(head_attention, xticklabels=tokens, yticklabels=tokens, cmap='viridis')\n",
    "    sns.heatmap(head_attention, cmap='viridis')\n",
    "    plt.title(f'Attention Head {head_index} in Layer {layer_index}')\n",
    "    plt.xlabel('Keys')\n",
    "    plt.ylabel('Queries')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Invalid layer index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_vertical_scores(\n",
    "    avg_mat: np.ndarray,\n",
    "    proximity_ignore: int = 20,\n",
    "    control_depth: bool = True,\n",
    "    score_type: str = \"mean\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate vertical attention scores from an averaged attention matrix.\n",
    "    \"\"\"\n",
    "    n = avg_mat.shape[0]\n",
    "    trius = np.triu_indices_from(avg_mat, k=1)\n",
    "    avg_mat = avg_mat.copy()\n",
    "    avg_mat[trius] = np.nan\n",
    "    trils = np.triu_indices_from(avg_mat, k=-proximity_ignore + 1)\n",
    "    avg_mat[trils] = np.nan\n",
    "\n",
    "    if control_depth:\n",
    "        per_row = np.sum(~np.isnan(avg_mat), axis=1)\n",
    "        avg_mat = stats.rankdata(avg_mat, axis=1, nan_policy=\"omit\") / per_row[:, None]\n",
    "\n",
    "    n = avg_mat.shape[-1]\n",
    "    vert_scores = []\n",
    "    for i in range(n):\n",
    "        vert_lines = avg_mat[i + proximity_ignore :, i]\n",
    "        if score_type == \"mean\":\n",
    "            vert_score = np.nanmean(vert_lines)\n",
    "        elif score_type == \"median\":\n",
    "            vert_score = np.nanmedian(vert_lines)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown score_type: {score_type}\")\n",
    "        vert_scores.append(vert_score)\n",
    "    return np.array(vert_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afceda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layer_head_scores = []\n",
    "for layer, layer_attn in enumerate(attention_weights):\n",
    "    layer_scores = []\n",
    "    for head in range(layer_attn.shape[1]):\n",
    "        avg_mat = layer_attn[0, head].detach().cpu().numpy()\n",
    "        vert_scores = get_vertical_scores(avg_mat, proximity_ignore=4, control_depth=False, score_type=\"mean\")\n",
    "        layer_scores.append(vert_scores)\n",
    "    all_layer_head_scores.append(layer_scores)\n",
    "all_layer_head_scores = np.array(all_layer_head_scores)  # shape: [num_layers, num_heads, seq_len - proximity_ignore]\n",
    "\n",
    "print(all_layer_head_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layer_head_scores[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d7c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def get_3d_ar_kurtosis(layer_head_vert_scores: np.ndarray) -> np.ndarray:\n",
    "    layer_head_kurts = stats.kurtosis(\n",
    "        layer_head_vert_scores, axis=2, fisher=True, bias=True, nan_policy=\"omit\"\n",
    "    )  # NaNs from the proximity ignorance\n",
    "    return layer_head_kurts\n",
    "\n",
    "# Compute kurtosis for all [layer][head] using vertical scores\n",
    "layer_head_kurtosis = get_3d_ar_kurtosis(all_layer_head_scores)\n",
    "print('Kurtosis shape:', layer_head_kurtosis.shape)\n",
    "print(layer_head_kurtosis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
